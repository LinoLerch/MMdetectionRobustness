{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness Benchmark results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surpress UserWarnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "def read_results_file(jobname, postfix=\"_results.pkl\"):\n",
    "    folder = \"evaluation/benchmark/\"\n",
    "    if postfix == \"_tpfp.pkl\":\n",
    "        folder += \"tpfp/\"\n",
    "    path = folder + \"rob-bm-full\" + jobname\n",
    "    res = mmcv.load(path + postfix)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get keys (corruptions) of result files\n",
    "for job in [\"-2_ff-baseline\",\"_ff-baseline\",\"-2_fb-add\",\"_fb-add\",\"_fb-mod\"]:\n",
    "    res = read_results_file(job)\n",
    "    last_sevs = list(res.values())[-1].keys()\n",
    "    print(f'{job}: {res.keys()} severities of last: {last_sevs} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the result dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dicts(names, postfix=\"_results.pkl\"):\n",
    "    dict_1 = read_results_file(names[0], postfix)\n",
    "    dict_2 = read_results_file(names[1], postfix)\n",
    "    dict_1.update(dict_2)\n",
    "    # save to file\n",
    "    folder = \"evaluation/benchmark/merged/\"\n",
    "    path = folder + \"rob-bm-merged_\" + names[2] + postfix\n",
    "    mmcv.dump(dict_1, path, file_format='pkl')\n",
    "    print(f'merged dict: {names[2]}\\n {dict_1.keys()} \\n')\n",
    "    return dict_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged dict: ff-baseline\n",
      " dict_keys(['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']) \n",
      "\n",
      "merged dict: fb-add\n",
      " dict_keys(['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']) \n",
      "\n",
      "merged dict: fb-mod\n",
      " dict_keys(['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for names in [[\"-2_ff-baseline\",\"-3_ff-baseline\",\"ff-baseline\"],\n",
    "            [\"-2_fb-add\",\"-3_fb-add\",\"fb-add\"],\n",
    "            [\"_fb-mod\",\"-3_fb-mod\",\"fb-mod\"]]:\n",
    "    #merge_dicts(names, postfix=\"_results.pkl\")\n",
    "    merge_dicts(names, postfix='_tpfp.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process true/false positive lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mmcv\n",
    "\n",
    "def count_tpfp(tpfp):\n",
    "    \"\"\"Count True Positves and False Positives per image \n",
    "        in: [class x image x tpfp] \n",
    "        out: [image x (count(tp),count(fp))]\n",
    "    \"\"\"\n",
    "    num_imgs = len(tpfp[0]['tp'])\n",
    "    tp_all = np.empty(num_imgs, dtype=object)\n",
    "    # go through classes\n",
    "    for tp_cl in tpfp:\n",
    "        # go through images\n",
    "        for (ind,item) in enumerate(tp_cl['tp']):\n",
    "            if item.shape!=(1,0):\n",
    "                if tp_all[ind] is None:\n",
    "                    tp_all[ind] = item[0]\n",
    "                else:\n",
    "                    tp_all[ind] = np.concatenate((tp_all[ind], item[0]), axis=0)\n",
    "    \n",
    "    tp_count = [(np.sum(tp_img == 1.0), np.sum(tp_img == 0.0)) for tp_img in tp_all]\n",
    "    return tp_count\n",
    "\n",
    "def transform_tpfp_keep_class(tpfp):\n",
    "    \"\"\"Transform TruePositve-FalsePositive list \n",
    "        from: [class x image x tpfp] to: [image x (class_idx, tpfp)]\n",
    "    \"\"\"\n",
    "    tp_all = np.empty(len(tpfp[0]['tp']), dtype=object)\n",
    "    # go through classes\n",
    "    for (cl_idx, tp_cl) in enumerate(tpfp):\n",
    "        # go through images\n",
    "        for (ind,item) in enumerate(tp_cl['tp']):\n",
    "            if item.shape!=(1,0):\n",
    "                item = item[0]\n",
    "                if tp_all[ind] is None:\n",
    "                    tp_all[ind] = (cl_idx, item)\n",
    "                else:\n",
    "                    tp_all[ind] = (tp_all[ind], (cl_idx, item))\n",
    "\n",
    "    return tp_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform and save tpfp-list for uncorrupted data (severity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in [\"ff-baseline\",\"fb-add\",\"fb-mod\"]:\n",
    "    path_read = f\"evaluation/benchmark/merged/rob-bm-merged_{filename}_tpfp.pkl\"\n",
    "    tpfp_old = mmcv.load(path_read)\n",
    "    tpfp_new = count_tpfp(tpfp_old['gaussian_noise'][0])\n",
    "    path_out = f\"evaluation/benchmark/significance_test/{filename}_tpfp-count_sev0.pkl\"\n",
    "    mmcv.dump(tpfp_new, path_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count nr of true and false positives overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpcount</th>\n",
       "      <th>fp count</th>\n",
       "      <th>fp free imgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ff-baseline</th>\n",
       "      <td>11105</td>\n",
       "      <td>27675</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb-add</th>\n",
       "      <td>10712</td>\n",
       "      <td>13708</td>\n",
       "      <td>1311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb-mod</th>\n",
       "      <td>10859</td>\n",
       "      <td>16354</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tpcount  fp count  fp free imgs\n",
       "ff-baseline    11105     27675           566\n",
       "fb-add         10712     13708          1311\n",
       "fb-mod         10859     16354          1116"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {}\n",
    "for filename in [\"ff-baseline\",\"fb-add\",\"fb-mod\"]:\n",
    "    path_read = f\"evaluation/benchmark/significance_test/{filename}_tpfp-count_sev0.pkl\"\n",
    "    tp_count_list = np.array(mmcv.load(path_read))\n",
    "    tp_count = np.sum(tp_count_list[:,0])\n",
    "    fp_count = np.sum(tp_count_list[:,1])\n",
    "    fp_imgs = np.sum(tp_count_list[:,1]==0)\n",
    "    data.update({filename: [tp_count, fp_count, fp_imgs]})\n",
    "pd.DataFrame.from_dict(data=data, orient='index', columns=[\"tpcount\", \"fp count\", \"fp free imgs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "format original TP-FP list:\n",
    "\n",
    "| 15  |  5   |  20 | 2 | 4952 | n |\n",
    "|---|---|---|---|-|-|\n",
    "|corruptions |severities | classes | tp, fp | images |detections|\n",
    "\n",
    "-----------\n",
    "format output of detections / ground truth:\n",
    "\n",
    "| 4952  |  20    |    n     |   5   |\n",
    "|---|---|---|---|\n",
    "|images |classes | detected bboxes | bbox + certainty |\n",
    "----------\n",
    "### Results Robustness Benchmark\n",
    "| model | P |  mPC   |  rPC |\n",
    "|---|--|---|---|\n",
    "|FF-Baseline | 0.801 | 0.489 | 60,5 % |\n",
    "|FB-Mod | 0.806 | 0.468 | 57,5 % |\n",
    "|FB-Add | 0.803 | 0.457 | 56,3 % |\n",
    "\n",
    "Performance on Clean Data [P] in AP50  \n",
    "Mean Performance under Corruption [mPC] in AP50  \n",
    "Relative Performance under Corruption [rPC] in %  \n",
    "\n",
    "### mAP per Severity\n",
    "| |ff_base  |fb_mod |fb_add|\n",
    "|-|---      |--     |   --|\n",
    "|0|\t0.801\t|0.806\t|0.803|\n",
    "|1|\t0.677\t|0.668\t|0.659|\n",
    "|2|\t0.594\t|0.579\t|0.570|\n",
    "|3|\t0.500\t|0.477\t|0.464|\n",
    "|4|\t0.384\t|0.353\t|0.340|\n",
    "|5|\t0.288\t|0.263\t|0.251|\n",
    "--------\n",
    "mPC calculation\n",
    "\n",
    "    mPC = np.mean(results[:15, 1:, :], axis=(0, 1))\n",
    "-> mean of 1500 APs\n",
    "| 15  |  5   |  20 | =1500 |\n",
    "|---|---|---|--|\n",
    "|corruptions |severities | classes | = total nr.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 20 classes of PASCAL VOC\n",
    " 0: aeroplane\n",
    " 1: bicycle\n",
    " 2: bird\n",
    " 3: boat\n",
    " 4: bottle\n",
    " 5: bus\n",
    " 6: car\n",
    " 7: cat\n",
    " 8: chair\n",
    " 9: cow\n",
    "10: diningtable\n",
    "11: dog\n",
    "12: horse\n",
    "13: motorbike\n",
    "14: person\n",
    "15: pottedplant\n",
    "16: sheep\n",
    "17: sofa\n",
    "18: train\n",
    "19: tvmonitor\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d99687c979af933fc8e3faa1bd1f4cb02dc6c777cd646580ab222f437424c44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
