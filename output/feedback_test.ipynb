{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet 50 output sizes of stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surpress UserWarnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 56, 56)\n",
      "(1, 512, 28, 28)\n",
      "(1, 1024, 14, 14)\n",
      "(1, 2048, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "from mmdet.models import ResNet\n",
    "import torch\n",
    "res50 = ResNet(depth=50)\n",
    "res50.eval()\n",
    "inputs =  torch.rand(1, 3, 224, 224)\n",
    "level_outputs = res50.forward(inputs)\n",
    "for level_out in level_outputs:\n",
    "    print(tuple(level_out.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adjust keys in checkpoint weights file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "root_path = \"../../../\"\n",
    "checkpoint = torch.load(f'{root_path}checkpoints/faster_rcnn_r50_fpn_1x_voc0712_20220320_192712-54bef0f3.pth')\n",
    "state_dict = checkpoint['state_dict']\n",
    "for key in list(state_dict.keys()):\n",
    "    state_dict[key.replace(\"backbone.\",\"backbone.resnet.\")] = state_dict.pop(key)\n",
    "checkpoint['state_dict'] = state_dict\n",
    "torch.save(checkpoint, f'{root_path}checkpoints/faster_rcnn_r50fb_fpn_1x_voc0712_20221208.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test inference FeedbackNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import init_detector, inference_detector\n",
    "import mmcv\n",
    "\n",
    "root_path = \"../../../\"\n",
    "# Specify the path to model config and checkpoint file\n",
    "config_file = f'{root_path}configs/pascal_voc/faster_rcnn_r50fbadd_fpn_1x_voc0712.py'\n",
    "checkpoint_file = f'{root_path}checkpoints/faster_rcnn_r50fb_fpn_1x_voc0712_20221208.pth'\n",
    "\n",
    "# build the model from a config file and a checkpoint file\n",
    "#model = init_detector(config_file, checkpoint_file, device='cpu')\n",
    "model = init_detector(config_file, checkpoint_file, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will only load it once\n",
    "img = mmcv.imread(f'{root_path}demo/demo.jpg')\n",
    "result = inference_detector(model, img)\n",
    "# visualize the results in a new window\n",
    "model.show_result(img, result, out_file=f'{root_path}output/result.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "# print(\"Model's state_dict:\")\n",
    "# for param_tensor in model.state_dict():\n",
    "#     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "#print(model)\n",
    "from torchsummary import summary\n",
    "summary(model)#, (1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(res50, (1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness Benchmark results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "def get_results(jobname,postfix=\"_results.pkl\"):\n",
    "    folder = \"evaluation/benchmark/\"\n",
    "    path = folder + \"rob-bm-full\" + jobname\n",
    "    return mmcv.load(path + postfix)\n",
    "\n",
    "#out = mmcv.load(folder+\"rob-bm_fb-mod.pkl\")\n",
    "#out_results = mmcv.load(folder+\"rob-bm_fb-mod_results.pkl\")\n",
    "#out_tpfp = mmcv.load(folder+\"rob-bm-full_fb-mod_tpfp.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2_ff-baseline: dict_keys(['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur']) severities of last: dict_keys([0, 1]) \n",
      "\n",
      "_ff-baseline: dict_keys(['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur']) severities of last: dict_keys([0, 1, 2, 3]) \n",
      "\n",
      "-2_fb-add: dict_keys(['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur']) severities of last: dict_keys([0, 1, 2, 3]) \n",
      "\n",
      "_fb-add: dict_keys(['gaussian_noise', 'shot_noise']) severities of last: dict_keys([0, 1, 2, 3]) \n",
      "\n",
      "_fb-mod: dict_keys(['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur']) severities of last: dict_keys([0, 1, 2, 3, 4, 5]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for job in [\"-2_ff-baseline\",\"_ff-baseline\",\"-2_fb-add\",\"_fb-add\",\"_fb-mod\"]:\n",
    "    res = get_results(job)\n",
    "    last_sevs = list(res.values())[-1].keys()\n",
    "    print(f'{job}: {res.keys()} severities of last: {last_sevs} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ap': 0.42176962},\n",
       " {'ap': 0.21062574},\n",
       " {'ap': 0.1496132},\n",
       " {'ap': 0.16844271},\n",
       " {'ap': 0.09090909},\n",
       " {'ap': 0.2705015},\n",
       " {'ap': 0.33141503},\n",
       " {'ap': 0.49906787},\n",
       " {'ap': 0.09090909},\n",
       " {'ap': 0.13461538},\n",
       " {'ap': 0.21941742},\n",
       " {'ap': 0.32032588},\n",
       " {'ap': 0.20525931},\n",
       " {'ap': 0.14242424},\n",
       " {'ap': 0.22470236},\n",
       " {'ap': 0.09090909},\n",
       " {'ap': 0.09090909},\n",
       " {'ap': 0.3027891},\n",
       " {'ap': 0.25945476},\n",
       " {'ap': 0.23072976}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_mod_res = get_results(\"_fb-mod\")\n",
    "fb_mod_res['zoom_blur'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the result dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dictionary:\n",
      "{'John': 15, 'Rick': 20, 'Misa': 12, 'Bonnie': 18, 'Matt': 16}\n"
     ]
    }
   ],
   "source": [
    "#Example\n",
    "dict_1 = {'John': 15, 'Rick': 10, 'Misa' : 12 }\n",
    "dict_2 = {'Bonnie': 18,'Rick': 20,'Matt' : 16 }\n",
    "dict_1.update(dict_2)\n",
    "print('Updated dictionary:')\n",
    "print(dict_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process true/false positive lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tpfp = get_results(\"_fb-mod\",\"_tpfp.pkl\")\n",
    "tp = out_tpfp['shot_noise'][5][12]['tp']\n",
    "tp_new = [(ind,item) for (ind,item) in enumerate(tp) if item.shape!=(1,0)]\n",
    "len(tp_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "format TP-FP list:\n",
    "\n",
    "| 15  |  5   |  20 | 2 | 4952 | n |\n",
    "|---|---|---|---|-|-|\n",
    "|corruptions |severities | classes | tp, fp | images |detections|\n",
    "\n",
    "-----------\n",
    "format output of detections:\n",
    "\n",
    "| 4952  |  20    |    n     |   5   |\n",
    "|---|---|---|---|\n",
    "|images |classes | detected bboxes | bbox + certainty |\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 20 classes of PASCAL VOC\n",
    " 0: aeroplane\n",
    " 1: bicycle\n",
    " 2: bird\n",
    " 3: boat\n",
    " 4: bottle\n",
    " 5: bus\n",
    " 6: car\n",
    " 7: cat\n",
    " 8: chair\n",
    " 9: cow\n",
    "10: diningtable\n",
    "11: dog\n",
    "12: horse\n",
    "13: motorbike\n",
    "14: person\n",
    "15: pottedplant\n",
    "16: sheep\n",
    "17: sofa\n",
    "18: train\n",
    "19: tvmonitor\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaCVproj",
   "language": "python",
   "name": "condacvproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "6d99687c979af933fc8e3faa1bd1f4cb02dc6c777cd646580ab222f437424c44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
