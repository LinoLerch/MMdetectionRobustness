{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet 50 output sizes of stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 56, 56)\n",
      "(1, 512, 28, 28)\n",
      "(1, 1024, 14, 14)\n",
      "(1, 2048, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "from mmdet.models import ResNet\n",
    "import torch\n",
    "res50 = ResNet(depth=50)\n",
    "res50.eval()\n",
    "inputs =  torch.rand(1, 3, 224, 224)\n",
    "level_outputs = res50.forward(inputs)\n",
    "for level_out in level_outputs:\n",
    "    print(tuple(level_out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchsummary. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\lerch\\anaconda3\\envs\\cv_project\\lib\\site-packages\\torchsummary\\torchsummary.py:140\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 140\u001b[0m         _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mto(device)(\u001b[39m*\u001b[39;49mx, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\lerch\\anaconda3\\envs\\cv_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\lerch\\documents\\studium\\master\\wise22\\project_cv\\code\\mmdetectionrobustness\\mmdet\\models\\backbones\\resnet.py:636\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 636\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[0;32m    637\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x)\n",
      "File \u001b[1;32mc:\\Users\\lerch\\anaconda3\\envs\\cv_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1208\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[1;32m-> 1208\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1209\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n",
      "File \u001b[1;32mc:\\Users\\lerch\\anaconda3\\envs\\cv_project\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\lerch\\anaconda3\\envs\\cv_project\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [2, 1, 3, 224, 224]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchsummary\u001b[39;00m \u001b[39mimport\u001b[39;00m summary\n\u001b[1;32m----> 2\u001b[0m summary(res50, (\u001b[39m1\u001b[39;49m, \u001b[39m3\u001b[39;49m, \u001b[39m224\u001b[39;49m, \u001b[39m224\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\lerch\\anaconda3\\envs\\cv_project\\lib\\site-packages\\torchsummary\\torchsummary.py:143\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    142\u001b[0m     executed_layers \u001b[39m=\u001b[39m [layer \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m summary_list \u001b[39mif\u001b[39;00m layer\u001b[39m.\u001b[39mexecuted]\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    144\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to run torchsummary. See above stack traces for more details. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExecuted layers up to: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(executed_layers)\n\u001b[0;32m    146\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m hooks \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to run torchsummary. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(res50, (1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test inference FeedbackNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust keys in checkpoint weights file\n",
    "import torch\n",
    "checkpoint = torch.load('../../checkpoints/faster_rcnn_r50_fpn_1x_voc0712_20220320_192712-54bef0f3.pth')\n",
    "state_dict = checkpoint['state_dict']\n",
    "for key in list(state_dict.keys()):\n",
    "    state_dict[key.replace(\"backbone.\",\"backbone.resnet.\")] = state_dict.pop(key)\n",
    "checkpoint['state_dict'] = state_dict\n",
    "torch.save(checkpoint, '../../checkpoints/faster_rcnn_r50fb_fpn_1x_voc0712_20221208.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lerch\\anaconda3\\envs\\cv_project\\lib\\site-packages\\mmcv\\__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ../../checkpoints/faster_rcnn_r50fb_fpn_1x_voc0712_20221208.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "missing keys in source state_dict: backbone.fb_con.conv.weight, backbone.fb_con.conv.bias\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import init_detector, inference_detector\n",
    "import mmcv\n",
    "\n",
    "# Specify the path to model config and checkpoint file\n",
    "config_file = '../../configs/pascal_voc/faster_rcnn_r50fb_fpn_1x_voc0712.py'\n",
    "checkpoint_file = '../../checkpoints/faster_rcnn_r50fb_fpn_1x_voc0712_20221208.pth'\n",
    "\n",
    "# build the model from a config file and a checkpoint file\n",
    "#model = init_detector(config_file, checkpoint_file, device='cpu')\n",
    "model = init_detector(config_file, checkpoint_file, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lerch\\documents\\studium\\master\\wise22\\project_cv\\code\\mmdetectionrobustness\\mmdet\\datasets\\utils.py:66: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# will only load it once\n",
    "img = mmcv.imread(\"../../demo/demo.jpg\")\n",
    "result = inference_detector(model, img)\n",
    "# visualize the results in a new window\n",
    "model.show_result(img, result, out_file='../../output/result.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─FeedbackResNet: 1-1                    --\n",
      "|    └─ResNet: 2-1                       --\n",
      "|    |    └─Conv2d: 3-1                  (9,408)\n",
      "|    |    └─BatchNorm2d: 3-2             (128)\n",
      "|    |    └─ReLU: 3-3                    --\n",
      "|    |    └─MaxPool2d: 3-4               --\n",
      "|    |    └─ResLayer: 3-5                (215,808)\n",
      "|    |    └─ResLayer: 3-6                1,219,584\n",
      "|    |    └─ResLayer: 3-7                7,098,368\n",
      "|    |    └─ResLayer: 3-8                14,964,736\n",
      "|    └─FBConnection: 2-2                 --\n",
      "|    |    └─Upsample: 3-9                --\n",
      "|    |    └─Conv2d: 3-10                 55,299\n",
      "|    |    └─LocalResponseNorm: 3-11      --\n",
      "├─FPN: 1-2                               --\n",
      "|    └─ModuleList: 2-3                   --\n",
      "|    |    └─ConvModule: 3-12             65,792\n",
      "|    |    └─ConvModule: 3-13             131,328\n",
      "|    |    └─ConvModule: 3-14             262,400\n",
      "|    |    └─ConvModule: 3-15             524,544\n",
      "|    └─ModuleList: 2-4                   --\n",
      "|    |    └─ConvModule: 3-16             590,080\n",
      "|    |    └─ConvModule: 3-17             590,080\n",
      "|    |    └─ConvModule: 3-18             590,080\n",
      "|    |    └─ConvModule: 3-19             590,080\n",
      "├─RPNHead: 1-3                           --\n",
      "|    └─CrossEntropyLoss: 2-5             --\n",
      "|    └─L1Loss: 2-6                       --\n",
      "|    └─Conv2d: 2-7                       590,080\n",
      "|    └─Conv2d: 2-8                       771\n",
      "|    └─Conv2d: 2-9                       3,084\n",
      "├─StandardRoIHead: 1-4                   --\n",
      "|    └─SingleRoIExtractor: 2-10          --\n",
      "|    |    └─ModuleList: 3-20             --\n",
      "|    └─Shared2FCBBoxHead: 2-11           --\n",
      "|    |    └─CrossEntropyLoss: 3-21       --\n",
      "|    |    └─L1Loss: 3-22                 --\n",
      "|    |    └─Linear: 3-23                 21,525\n",
      "|    |    └─Linear: 3-24                 82,000\n",
      "|    |    └─ModuleList: 3-25             --\n",
      "|    |    └─ModuleList: 3-26             13,895,680\n",
      "|    |    └─ModuleList: 3-27             --\n",
      "|    |    └─ModuleList: 3-28             --\n",
      "|    |    └─ModuleList: 3-29             --\n",
      "|    |    └─ModuleList: 3-30             --\n",
      "|    |    └─ReLU: 3-31                   --\n",
      "=================================================================\n",
      "Total params: 41,500,855\n",
      "Trainable params: 41,275,511\n",
      "Non-trainable params: 225,344\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─FeedbackResNet: 1-1                    --\n",
       "|    └─ResNet: 2-1                       --\n",
       "|    |    └─Conv2d: 3-1                  (9,408)\n",
       "|    |    └─BatchNorm2d: 3-2             (128)\n",
       "|    |    └─ReLU: 3-3                    --\n",
       "|    |    └─MaxPool2d: 3-4               --\n",
       "|    |    └─ResLayer: 3-5                (215,808)\n",
       "|    |    └─ResLayer: 3-6                1,219,584\n",
       "|    |    └─ResLayer: 3-7                7,098,368\n",
       "|    |    └─ResLayer: 3-8                14,964,736\n",
       "|    └─FBConnection: 2-2                 --\n",
       "|    |    └─Upsample: 3-9                --\n",
       "|    |    └─Conv2d: 3-10                 55,299\n",
       "|    |    └─LocalResponseNorm: 3-11      --\n",
       "├─FPN: 1-2                               --\n",
       "|    └─ModuleList: 2-3                   --\n",
       "|    |    └─ConvModule: 3-12             65,792\n",
       "|    |    └─ConvModule: 3-13             131,328\n",
       "|    |    └─ConvModule: 3-14             262,400\n",
       "|    |    └─ConvModule: 3-15             524,544\n",
       "|    └─ModuleList: 2-4                   --\n",
       "|    |    └─ConvModule: 3-16             590,080\n",
       "|    |    └─ConvModule: 3-17             590,080\n",
       "|    |    └─ConvModule: 3-18             590,080\n",
       "|    |    └─ConvModule: 3-19             590,080\n",
       "├─RPNHead: 1-3                           --\n",
       "|    └─CrossEntropyLoss: 2-5             --\n",
       "|    └─L1Loss: 2-6                       --\n",
       "|    └─Conv2d: 2-7                       590,080\n",
       "|    └─Conv2d: 2-8                       771\n",
       "|    └─Conv2d: 2-9                       3,084\n",
       "├─StandardRoIHead: 1-4                   --\n",
       "|    └─SingleRoIExtractor: 2-10          --\n",
       "|    |    └─ModuleList: 3-20             --\n",
       "|    └─Shared2FCBBoxHead: 2-11           --\n",
       "|    |    └─CrossEntropyLoss: 3-21       --\n",
       "|    |    └─L1Loss: 3-22                 --\n",
       "|    |    └─Linear: 3-23                 21,525\n",
       "|    |    └─Linear: 3-24                 82,000\n",
       "|    |    └─ModuleList: 3-25             --\n",
       "|    |    └─ModuleList: 3-26             13,895,680\n",
       "|    |    └─ModuleList: 3-27             --\n",
       "|    |    └─ModuleList: 3-28             --\n",
       "|    |    └─ModuleList: 3-29             --\n",
       "|    |    └─ModuleList: 3-30             --\n",
       "|    |    └─ReLU: 3-31                   --\n",
       "=================================================================\n",
       "Total params: 41,500,855\n",
       "Trainable params: 41,275,511\n",
       "Non-trainable params: 225,344\n",
       "================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "# print(\"Model's state_dict:\")\n",
    "# for param_tensor in model.state_dict():\n",
    "#     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "#print(model)\n",
    "from torchsummary import summary\n",
    "summary(model)#, (1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('cv_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d99687c979af933fc8e3faa1bd1f4cb02dc6c777cd646580ab222f437424c44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
